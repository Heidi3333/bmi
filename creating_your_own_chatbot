# -*- coding: utf-8 -*-
"""Creating Your Own Chatbot

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CGANGseGbh8OyXIbARyGbf7RnV5M8j08
"""




import nltk
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from nltk.probability import FreqDist
import streamlit as st
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
import re

nltk.download('stopwords')
nltk.download('punkt')
# Read the content of the CSV file
with open("data.csv", "r") as file:
    data = file.read()

# Preprocess the data
def preprocess(text):
    # Convert text to lowercase
    text = text.lower()

    # Remove punctuation
    text = re.sub(r'[^\w\s]', '', text)

    # Tokenize the text
    tokens = word_tokenize(text)

    # Remove stop words
    stop_words = set(stopwords.words('english'))
    tokens = [token for token in tokens if token not in stop_words]

    # Join the tokens back into a single string
    preprocessed_text = ' '.join(tokens)

# Define the similarity function
def get_most_relevant_sentence(query, sentences):
    # Preprocess the query
    preprocessed_query = preprocess(query)

    # Preprocess the sentences
    preprocessed_sentences = [preprocess(sentence) for sentence in sentences]

    # Create a TfidfVectorizer
    vectorizer = TfidfVectorizer()

    # Compute the TF-IDF matrix
    tfidf_matrix = vectorizer.fit_transform(preprocessed_sentences + [preprocessed_query])

    # Compute the cosine similarity matrix
    similarity_matrix = cosine_similarity(tfidf_matrix[:-1], tfidf_matrix[-1])

    # Get the index of the most similar sentence
    most_similar_index = similarity_matrix.argmax()

    # Return the most relevant sentence
    return sentences[most_similar_index]

# Define the chatbot function
def chatbot(query):
    # Load the data
    data = pd.read_csv('data.csv')

    # Get the sentences
    sentences = data['District name'].tolist()

    # Get the most relevant sentence
    most_relevant_sentence = get_most_relevant_sentence(query, sentences)

    return most_relevant_sentence

# Create a Streamlit app
def main():
    st.title("School Attendance Chatbot")
    query = st.text_input("Ask a question")
    if query:
        response = chatbot(query)
        st.text(response)

if __name__ == '__main__':
    main()
